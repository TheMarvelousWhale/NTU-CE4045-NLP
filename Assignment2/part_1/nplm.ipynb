{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16761e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "import data_fnn as data\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574feee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_split(orig_corpus, dataset, n):\n",
    "    # This function breaks corpus into [context, target]\n",
    "    # For e.g., in trigram, the tensor returned would be [C(n-2), C(n-1), T]\n",
    "    ngram = []\n",
    "    data_len = len(dataset)\n",
    "    eos_id = corpus.dictionary.word2idx['<eos>']       \n",
    "    for i, tokenid in enumerate(dataset):\n",
    "        if i+n<data_len:\n",
    "            temp_gram = dataset[i:i+n+1].view(-1)\n",
    "            if eos_id in temp_gram[0:n]:\n",
    "                continue\n",
    "            ngram.append(temp_gram)\n",
    "    fin_ngram=torch.stack(ngram)\n",
    "    return fin_ngram\n",
    "\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, dataloader, gpu):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(dataloader):\n",
    "            context_tensor = data_tensor[:,0:CONTEXT_SIZE]\n",
    "            target_tensor = data_tensor[:,CONTEXT_SIZE]\n",
    "            context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parameters\n",
    "gpu = 0 \n",
    "# word vectors size\n",
    "EMBEDDING_DIM = 200\n",
    "CONTEXT_SIZE = 7\n",
    "BATCH_SIZE = 512\n",
    "shared = True\n",
    "# hidden units\n",
    "if shared:\n",
    "    H = 200\n",
    "else:\n",
    "    H = 100\n",
    "torch.manual_seed(42)\n",
    "learn_rate = 1e-3\n",
    "\n",
    "# check if gpu is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = './data/wikitext-2'\n",
    "corpus = data.Corpus(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = corpus.train\n",
    "val_set = corpus.valid\n",
    "test_set = corpus.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram = ngram_split(corpus, train_set, CONTEXT_SIZE)\n",
    "val_ngram = ngram_split(corpus, val_set, CONTEXT_SIZE)\n",
    "test_ngram = ngram_split(corpus, test_set, CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a56d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ngram, batch_size = BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(val_ngram, batch_size = BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(train_ngram, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "vocab_len = len(corpus.dictionary)\n",
    "# vocab_len = len(vocab)\n",
    "\n",
    "# create model\n",
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "model = model.FNNModel(vocab_len, EMBEDDING_DIM, CONTEXT_SIZE, H)\n",
    "\n",
    "# load it to gpu\n",
    "model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_ppl = 999\n",
    "best_model_path = None\n",
    "for epoch in range(5):\n",
    "    st = time.time()\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(train_loader):\n",
    "        context_tensor = data_tensor[:,0:CONTEXT_SIZE]\n",
    "        target_tensor = data_tensor[:,CONTEXT_SIZE]\n",
    "#         print(context_tensor)\n",
    "#         print(target_tensor)\n",
    "        context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % 500 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}\".format(it, epoch, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, dev_loader, gpu)\n",
    "    ppl = math.exp(dev_loss)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}; Perplexity: {}\".format(epoch, dev_acc, dev_loss, ppl))\n",
    "#    if dev_acc > best_acc:\n",
    "    if ppl < best_ppl:\n",
    "        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_ppl, ppl))\n",
    "        best_ppl = ppl\n",
    "        # set best model path\n",
    "        best_model_path = 'best_model_{}_gram_{}_{}H.dat'.format(CONTEXT_SIZE+1, epoch, H)\n",
    "        # saving best model\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c0faa9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d41263",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_loss = evaluate(model, loss_function, test_loader, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Perplexity:\", math.exp(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca5ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_shared.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5f032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c23ce628",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de12304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import model\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dda230",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.Corpus('./data/wikitext-2')\n",
    "ntokens = len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_shared.pt'\n",
    "device = torch.device(\"cuda\")\n",
    "model = torch.load(model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc47a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = dict(model.named_children())\n",
    "embedding_size = l['embeddings'].embedding_dim # 200\n",
    "input_layer_dim = l['linear1'].in_features # 1400\n",
    "context_size = int(input_layer_dim/embedding_size) # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc48dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corpus = torch.cat((corpus.train, corpus.valid, corpus.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d10a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_pos = random.randint(0, len(full_corpus)-context_size)\n",
    "seed_span = full_corpus[seed_pos:seed_pos+context_size] # Pick random span from corpus\n",
    "generated_text=seed_span.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39313ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i in range(15):\n",
    "    with torch.no_grad():\n",
    "        output = model(generated_text[-7:])\n",
    "        word_id = torch.argmax(output, dim=1)\n",
    "        generated_text = torch.cat((generated_text,word_id))\n",
    "        print(generated_text[-8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4926234",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = generated_text.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e95e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in enumerate(generated_text):\n",
    "    if index == 7: \n",
    "        print(\" | \", end = \"\")\n",
    "    print(corpus.dictionary.idx2word[i], end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389cb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a9ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

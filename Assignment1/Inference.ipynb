{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ae1305-87c0-4e2a-889b-aed7ec031396",
   "metadata": {},
   "source": [
    "# Inference pipeline for Chiayu \n",
    "\n",
    "This page shows how to run a trained model to get its prediction \\\n",
    "What is needed is:\n",
    "* the model file in pt \n",
    "* the config.json for the initialization of the model architecture\n",
    "* the vocab and merges file for the tokenizer -- we will then add our tokens inside so i dont have more files to deal with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249c3745-b799-4323-a4b0-161fc1249571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining ,AutoConfig\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fd8999-e328-4a4a-8d02-7f2ca09f8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './colab_output/'\n",
    "model_output = model_dir + 'stilted-snowball-14.pt'\n",
    "\n",
    "\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir) \n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_dir+'config.json', \n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id,\n",
    "                                    sep_token_id=tokenizer.sep_token_id,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    output_hidden_states=False)\n",
    "\n",
    "model = AutoModelForPreTraining.from_pretrained(model_output, config=model_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db203ef7-f7b3-4aaf-82e4-0532c05b8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: I ordered the Chicken and Bologna.  The chicken was bland...but I had to order it again after a week of eating there for lunch so that we could have some decent food at home! We were very disappointed with how much they put on our table when ordering from us as well!!\n",
      "We got seated right away but didn't realize why until about 15 minutes later which took forever (it's an hour). There wasn'nt even any sauce or dressing in either dish except salt..the meat tasted like sausage instead....so salty!!! Our waitress came out feeling bad because she knew what would happen if this happened - my boyfriend just walked by me looking miserable without having his meal prepared properly.....he never left her alone during dinner time, he only wanted one person working around him! He is extremely unprofessional here and will NEVER leave you anywhere else!!!!\n",
      "\n",
      "\n",
      "2: This place has been my go-to spot for a while now. They have some of the best breakfast in town and I highly recommend it to anyone looking forward on their next trip! I've never had an issue with service or customer care but they are so friendly that you can always get your food ready when needed (especially if there's someone waiting). \n",
      "The only reason why this is still here as well isn't because we live close by - our server was very nice enough during lunch time at work...he even brought his own fork to take home after he got up from doing work before leaving to go back into business later than usual :)\n",
      "\n",
      "\n",
      "3: I came here to try out the new Waffle House. \n",
      "We ordered a waffles for our waitress and she had an order of 2 that was missing two pieces! We asked about it but they said no problem so we were told this would be done by 8:30pm on Monday night (Saturday). The food is great... I got my wings with egg whites instead because i think there are more sauce options in store so why wouldn't you add some extra? They also have the chicken kabob which makes me want one too!!  My only complaint from their menu though - especially since your server seems very nice- isnso sweet.. we'll probably go back later when other places get better service\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#device = 'cpu' \n",
    "device = 'cuda'\n",
    "\n",
    "rating = 'boring, not funny, not funny, horrible'\n",
    "\n",
    "def gen_suggestions(rating,model):\n",
    "    prompt = SPECIAL_TOKENS['bos_token'] + rating + SPECIAL_TOKENS['sep_token']\n",
    "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
    "    model.to(device)\n",
    "    model.eval();\n",
    "\n",
    "      # Top-p (nucleus) text generation (10 samples):\n",
    "    sample_outputs = model.generate(generated, \n",
    "                                      do_sample=True,   \n",
    "                                      min_length=50, \n",
    "                                      max_length=256,\n",
    "                                      top_k=30,                                 \n",
    "                                      top_p=0.7,        \n",
    "                                      temperature=0.9,\n",
    "                                      repetition_penalty=2.0,\n",
    "                                      num_return_sequences=3\n",
    "                                      )\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "            text = tokenizer.decode(sample_output, skip_special_tokens=True)   \n",
    "\n",
    "            print(\"{}: {}\\n\\n\".format(i+1,  text[len(rating):]))\n",
    "\n",
    "gen_suggestions('boring, not funny, not funny, horrible',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea3fa4-50b0-4e15-aad8-e00dd6dfa390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

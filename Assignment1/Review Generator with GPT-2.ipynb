{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8432,
     "status": "ok",
     "timestamp": 1631525415325,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "OxHckUCRZEAp",
    "outputId": "06eb4e03-adec-49a8-84e3-73bbf2b73190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.6 ms, sys: 31 ms, total: 90.7 ms\n",
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6mUPfr0ZQS9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining ,AutoConfig\n",
    "from transformers import TrainingArguments,Trainer\n",
    "import torch\n",
    "import wandb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1631525422097,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "Dwo-ujqwwmv-",
    "outputId": "9550f520-fea0-4c0e-cd6d-e34c15a04aaa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1631525425860,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "OhOI6K2EbAq0",
    "outputId": "282825ad-f436-4495-b48f-a6e2d047a578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 13 09:30:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1631525433182,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "Y1jutyr6ZeqX",
    "outputId": "0c24492d-3c39-4900-df13-e7f64e762ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1631525435175,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "AH9Inq5aZo5r",
    "outputId": "57da6a55-015f-4e26-d4eb-919c13e573ae"
   },
   "outputs": [],
   "source": [
    "import json,random\n",
    "\n",
    "sample_file = '/content/drive/MyDrive/Colab Notebook/reviewSelected100.json'\n",
    "\n",
    "#data importing and formating\n",
    "def process_raw_data(data_in_weird_format_file):\n",
    "    with open(data_in_weird_format_file,'r',encoding='latin-1') as f:\n",
    "        raw_data = f.read()\n",
    "    data = raw_data.split('}\\n')\n",
    "    return [json.loads(x+'}') for x in data if x != '']  #load the json straight-awway\n",
    "\n",
    "\n",
    "\n",
    "data = process_raw_data(sample_file)\n",
    "print(f'Processed {len(data)} lines of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "executionInfo": {
     "elapsed": 6261,
     "status": "ok",
     "timestamp": 1631525448642,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "XCzhemgOaTRe",
    "outputId": "2c0e4b51-eb8d-4c82-b869-8457dea61f10"
   },
   "outputs": [],
   "source": [
    "wandb.init(project='CE4045-Review-Generator',entity='groupx')\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "\n",
    "config.TRAIN_DEV_SPLIT = 0.9\n",
    "config.UNFREEZE_LAST_N = 7          #the number of learnable layer\n",
    "config.MAXLEN = 256                 # max length of the tensor \n",
    "config.EPOCHS = 5\n",
    "config.TRAIN_BATCHSIZE = 4\n",
    "config.LR              = 5e-4\n",
    "config.EPS             = 1e-8\n",
    "config.WARMUP_STEPS    = 1e2\n",
    "\n",
    "config.checkpoint = 'distilgpt2'   #choose this because it was causal LM and trained on next word predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3y61y22YajyE"
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, randomize=True):\n",
    "        \n",
    "        #initializing from list of json \n",
    "        rating, text = [], []\n",
    "        for _json in data:\n",
    "            rating.append(myDataset.rating_score_to_words(_json))\n",
    "            text.append(_json['text'])\n",
    "\n",
    "        self.randomize = randomize\n",
    "        self.tokenizer = tokenizer \n",
    "        self.rating    = rating\n",
    "        self.text      = text\n",
    "\n",
    "    @staticmethod\n",
    "    def rating_score_to_words(_json):\n",
    "        cool_map = {0:\"boring\",1:\"so so\",2:\"cool\",3:\"very cool\",4:\"extremely cool\"}\n",
    "        cool_rating = cool_map.get(int(math.log(_json[\"cool\"] + 1)),\"cool\")\n",
    "        fun_map = {0:\"not funny\",1:\"kind of funny\",2:\"funny\",3:\"very funny\",4:\"extremely fun\"}\n",
    "        fun_rating = fun_map.get(int(math.log(_json[\"funny\"] + 1)),\"funny\")\n",
    "        useful_map = {0:\"not useful\",1:\"kind of useful\",2:\"useful\",3:\"very useful\",4:\"extremely useful\"}\n",
    "        useful_rating = useful_map.get(int(math.log(_json[\"useful\"] + 1)),\"useful\")\n",
    "        quality_map = {1:\"horrible\",2:\"bad\",3:\"ok\",4:\"good\",5:\"excellent\"}\n",
    "        quality_rating = quality_map.get(_json[\"stars\"],\"ok\")\n",
    "        return ', '.join([cool_rating,fun_rating,useful_rating,quality_rating])\n",
    "        \n",
    "    #possible to use for keywords prompt\n",
    "    @staticmethod\n",
    "    def join_keywords(keywords, randomize=True):\n",
    "        N = len(keywords)\n",
    "\n",
    "        #random sampling and shuffle\n",
    "        if randomize: \n",
    "            M = random.choice(range(N+1))\n",
    "            keywords = keywords[:M]\n",
    "            random.shuffle(keywords)\n",
    "\n",
    "        return ' '.join(keywords)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        rating = self.rating[i]\n",
    "        #kw = self.join_keywords(keywords, self.randomize)\n",
    "        \n",
    "        _input = SPECIAL_TOKENS['bos_token'] + \\\n",
    "                 rating + SPECIAL_TOKENS['sep_token'] + \\\n",
    "                self.text[i] + SPECIAL_TOKENS['eos_token']\n",
    "\n",
    "        encodings_dict = tokenizer(_input,                                   \n",
    "                                   truncation=True, \n",
    "                                   max_length=256, \n",
    "                                   padding=\"max_length\")   \n",
    "        \n",
    "        input_ids = encodings_dict['input_ids']\n",
    "        attention_mask = encodings_dict['attention_mask']\n",
    "        \n",
    "        #label and input_ids same will auto shift 1 for next word prediction task -- GPT-2 model design\n",
    "        \n",
    "        return {'label': torch.tensor(input_ids),\n",
    "                'input_ids': torch.tensor(input_ids), \n",
    "                'attention_mask': torch.tensor(attention_mask)}\n",
    "\n",
    "    \n",
    "#it's abit of a waste why i use this function    \n",
    "    \n",
    "def split_data(data, S=0.8):\n",
    "    # Shuffle ids\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Split into training and validation sets    \n",
    "    train_size = int(S * len(data))\n",
    "\n",
    "    return data[:train_size],data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16005,
     "status": "ok",
     "timestamp": 1631525474385,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "HPh90dBda5cH",
    "outputId": "49eb77c3-58d2-4154-88fb-a425b20fa687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13,770 samples for training, and 1,530 samples for validation testing\n"
     ]
    }
   ],
   "source": [
    "#set up tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.checkpoint) \n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
    "\n",
    "#set up data\n",
    "train_data, val_data = split_data(data,config.TRAIN_DEV_SPLIT)\n",
    "\n",
    "train_dataset = myDataset(train_data, tokenizer)\n",
    "val_dataset = myDataset(val_data, tokenizer)\n",
    "\n",
    "print(f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing')\n",
    "\n",
    "#set up model\n",
    "model_config = AutoConfig.from_pretrained(config.checkpoint, \n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id,\n",
    "                                    sep_token_id=tokenizer.sep_token_id,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    output_hidden_states=False)\n",
    "\n",
    "model = AutoModelForPreTraining.from_pretrained(config.checkpoint, config=model_config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# - Freeze all layers except last n:\n",
    "\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "for i, m in enumerate(model.transformer.h):        \n",
    "    #Only un-freeze the last n transformer blocks\n",
    "    if i+1 > 12 - config.UNFREEZE_LAST_N:\n",
    "        for parameter in m.parameters():\n",
    "            parameter.requires_grad = True \n",
    "\n",
    "for parameter in model.transformer.ln_f.parameters():        \n",
    "    parameter.requires_grad = True\n",
    "\n",
    "for parameter in model.lm_head.parameters():        \n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6064467,
     "status": "ok",
     "timestamp": 1631531542923,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "WljTRqkma9nD",
    "outputId": "b42dbbf4-623b-4380-8c46-66f27a48acc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13770\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17215\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17215' max='17215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17215/17215 1:40:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.729100</td>\n",
       "      <td>1.719679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.605200</td>\n",
       "      <td>1.697389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.495600</td>\n",
       "      <td>1.700388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.426100</td>\n",
       "      <td>1.717995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.383700</td>\n",
       "      <td>1.740404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output/checkpoint-500\n",
      "Configuration saved in ./output/checkpoint-500/config.json\n",
      "Model weights saved in ./output/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-1000\n",
      "Configuration saved in ./output/checkpoint-1000/config.json\n",
      "Model weights saved in ./output/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-1500\n",
      "Configuration saved in ./output/checkpoint-1500/config.json\n",
      "Model weights saved in ./output/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-2000\n",
      "Configuration saved in ./output/checkpoint-2000/config.json\n",
      "Model weights saved in ./output/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-2500\n",
      "Configuration saved in ./output/checkpoint-2500/config.json\n",
      "Model weights saved in ./output/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-3000\n",
      "Configuration saved in ./output/checkpoint-3000/config.json\n",
      "Model weights saved in ./output/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-3000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1530\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./output/checkpoint-3500\n",
      "Configuration saved in ./output/checkpoint-3500/config.json\n",
      "Model weights saved in ./output/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-4000\n",
      "Configuration saved in ./output/checkpoint-4000/config.json\n",
      "Model weights saved in ./output/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-4500\n",
      "Configuration saved in ./output/checkpoint-4500/config.json\n",
      "Model weights saved in ./output/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-5000\n",
      "Configuration saved in ./output/checkpoint-5000/config.json\n",
      "Model weights saved in ./output/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-5500\n",
      "Configuration saved in ./output/checkpoint-5500/config.json\n",
      "Model weights saved in ./output/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-6000\n",
      "Configuration saved in ./output/checkpoint-6000/config.json\n",
      "Model weights saved in ./output/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-6500\n",
      "Configuration saved in ./output/checkpoint-6500/config.json\n",
      "Model weights saved in ./output/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-6500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1530\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./output/checkpoint-7000\n",
      "Configuration saved in ./output/checkpoint-7000/config.json\n",
      "Model weights saved in ./output/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-7500\n",
      "Configuration saved in ./output/checkpoint-7500/config.json\n",
      "Model weights saved in ./output/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-8000\n",
      "Configuration saved in ./output/checkpoint-8000/config.json\n",
      "Model weights saved in ./output/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-8500\n",
      "Configuration saved in ./output/checkpoint-8500/config.json\n",
      "Model weights saved in ./output/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-9000\n",
      "Configuration saved in ./output/checkpoint-9000/config.json\n",
      "Model weights saved in ./output/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-9500\n",
      "Configuration saved in ./output/checkpoint-9500/config.json\n",
      "Model weights saved in ./output/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-10000\n",
      "Configuration saved in ./output/checkpoint-10000/config.json\n",
      "Model weights saved in ./output/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1530\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./output/checkpoint-10500\n",
      "Configuration saved in ./output/checkpoint-10500/config.json\n",
      "Model weights saved in ./output/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-11000\n",
      "Configuration saved in ./output/checkpoint-11000/config.json\n",
      "Model weights saved in ./output/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-11500\n",
      "Configuration saved in ./output/checkpoint-11500/config.json\n",
      "Model weights saved in ./output/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-12000\n",
      "Configuration saved in ./output/checkpoint-12000/config.json\n",
      "Model weights saved in ./output/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-12500\n",
      "Configuration saved in ./output/checkpoint-12500/config.json\n",
      "Model weights saved in ./output/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-13000\n",
      "Configuration saved in ./output/checkpoint-13000/config.json\n",
      "Model weights saved in ./output/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-13500\n",
      "Configuration saved in ./output/checkpoint-13500/config.json\n",
      "Model weights saved in ./output/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-13500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1530\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./output/checkpoint-14000\n",
      "Configuration saved in ./output/checkpoint-14000/config.json\n",
      "Model weights saved in ./output/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-14500\n",
      "Configuration saved in ./output/checkpoint-14500/config.json\n",
      "Model weights saved in ./output/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-15000\n",
      "Configuration saved in ./output/checkpoint-15000/config.json\n",
      "Model weights saved in ./output/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-15500\n",
      "Configuration saved in ./output/checkpoint-15500/config.json\n",
      "Model weights saved in ./output/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-16000\n",
      "Configuration saved in ./output/checkpoint-16000/config.json\n",
      "Model weights saved in ./output/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-16500\n",
      "Configuration saved in ./output/checkpoint-16500/config.json\n",
      "Model weights saved in ./output/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to ./output/checkpoint-17000\n",
      "Configuration saved in ./output/checkpoint-17000/config.json\n",
      "Model weights saved in ./output/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-17000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1530\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./output/\n",
      "Configuration saved in ./output/config.json\n",
      "Model weights saved in ./output/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/tokenizer_config.json\n",
      "Special tokens file saved in ./output/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/\",\n",
    "    num_train_epochs=config.EPOCHS,\n",
    "    per_device_train_batch_size=config.TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=config.TRAIN_BATCHSIZE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #no_cuda=False,                                            #disable this  if u want to use CUDA\n",
    "    warmup_steps=config.WARMUP_STEPS,    \n",
    "    learning_rate=config.LR,\n",
    "    adam_epsilon=config.EPS,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,    \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "\n",
    "torch.save(model.state_dict(),f'./{wandb.run.name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eN344WkSk_gx"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "def gen_suggestions(rating,model):\n",
    "  prompt = SPECIAL_TOKENS['bos_token'] + rating + SPECIAL_TOKENS['sep_token']\n",
    "          \n",
    "  generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
    "\n",
    "  model.eval();\n",
    "\n",
    "  # Top-p (nucleus) text generation (10 samples):\n",
    "  sample_outputs = model.generate(generated, \n",
    "                                  do_sample=True,   \n",
    "                                  min_length=50, \n",
    "                                  max_length=256,\n",
    "                                  top_k=30,                                 \n",
    "                                  top_p=0.7,        \n",
    "                                  temperature=0.9,\n",
    "                                  repetition_penalty=2.0,\n",
    "                                  num_return_sequences=3\n",
    "                                  )\n",
    "\n",
    "  for i, sample_output in enumerate(sample_outputs):\n",
    "      text = tokenizer.decode(sample_output, skip_special_tokens=True)   \n",
    "\n",
    "      print(\"{}: {}\\n\\n\".format(i+1,  text[len(rating):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2773,
     "status": "ok",
     "timestamp": 1631531579739,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "RC1tHh3El4cb",
    "outputId": "9e88842c-6dcb-4163-c34e-a44f197f1884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: I'm used to seeing the reviews but this place is terrible. The food here was so bad I went to a different location and ordered a chicken breast kabob plate and the chicken breast kabob came with white rice instead of salad (which they charge). When my husband received his plate it looked like he had an excess fatty liver inside which was completely unacceptable. My friend also ordered the \"beef\" and said that the waiter didn't even apologize for doing what we were told... I left him hungry and hungry and I will never go back.\n",
      "\n",
      "\n",
      "2: I was told this place is closed. The girl that works there did my nails and she kept screaming at me while I waited for a few minutes, then when someone finally came in to fix it the manager said no one greeted him or let her know. She basically walked away and was not friendly enough!\n",
      "\n",
      "\n",
      "3: I've been to a lot of dueling piano bars and this one was the most disappointing.  The bartenders were really rude - but it's still very loud with my obnoxious female bartender.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_suggestions('boring, not funny, not useful, horrible',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5977,
     "status": "ok",
     "timestamp": 1631532884992,
     "user": {
      "displayName": "Yong Shan Jie",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02191073202604714696"
     },
     "user_tz": -480
    },
    "id": "wCaGBktDlGJ5",
    "outputId": "1d35ab40-869d-48b3-d105-7c1cbc4c743f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: We had an amazing experience with OnQ Property Management.  They are very friendly and professional.  I highly recommend them to anyone looking for a property management experience!  We were in the market at about 6:30pm on our second day of renting out home (which was later confirmed).\n",
      "When we arrived they called me immediately and explained that it would be done within 45 minutes, so when there wasn't any waiting time or even more people came over after us until 2PM!! After confirming my receipt online please ask if you want another appointment ASAP.\n",
      "\n",
      "\n",
      "2: We have been looking for a place to get good BBQ food and this is one of those places.\n",
      "It's located in Richlane Mall on the corner from East Washington E & Hwy 7. It has several options:  Chicken Pho (sweet bean) with rice or salad along side, Beef Noodle Soup ($8). The staff are very friendly, which is nice because they do offer free hot dishes! We also got two types - Hot and Sour Pork Rice($12)! They were pretty quick but I had heard that we needed more variety so our food came out fast enough that when it came time she suggested adding soup bases such as chicken, beef brisket...so instead you can substitute your own noodles for whatever. For $9 all costs go towards Fried Fish Sauce + Squid Tempura(!) plus tax! You're getting 3 sides per plate and each dish comes at least 2/3 pieces of meat and 4 small skewers. All around reasonable prices.  My husband got the spicy pork rice noodle soup and he was super pleased!! I've eaten there twice now since it wasn't really fresh yet!!! He said his meal included tofu, bean sprouts topped off by onions, black bean and carrots.\n",
      "\n",
      "\n",
      "3: This is one of my favorite places to get a colonic and I've been here twice now!\n",
      "The first time you walk in the door you see me with your hands up. You're greeted by a friendly receptionist who takes a picture right after someone puts your arm on it or asks if they want anything else done to you while your body warms down your throat like a baby growling. The girl who cleanses me off with no constipation is super sweet and has such an amazing personality! She makes you feel so welcome and so comfortable while I'm there.  Also very attentive at getting her attention.\n",
      "I ordered 2 packages: One for $6-8 (delicious) as well which included soup bases that came w/o ice cream(not sure what's called \"spam milk\" but still delicious!) And two extra ones ($7-$10). They also include ketchup and hot sauce along side...all were really good!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_suggestions('cool, funny, useful, excellent',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awmUgj7wmDrN"
   },
   "outputs": [],
   "source": [
    "! rm -rf wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7n2CQ4b3psA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Review Generator with GPT-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
